{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b42e1c1-094d-403d-a523-07b77453bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398f60b6-f9f1-457a-bcb6-c234104a9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzers = ['zest', 'bedivfuzz', 'bedivfuzz-split']\n",
    "subjects = ['ant', 'bcel', 'chocopy', 'closure', 'maven', 'nashorn', 'pngj', 'rhino', 'tomcat']\n",
    "num_trials = 30\n",
    "timeout = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e0d9b3-0be7-4746-a66b-fac1cbc8d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_trial_df(experiment_name: str, fuzzer: str, subject: str, trial: int):\n",
    "    df = pd.read_csv(\n",
    "        os.path.join('results', experiment_name, fuzzer, subject, f'trial-{trial}', 'plot_data'),\n",
    "        skipinitialspace=True\n",
    "    )\n",
    "\n",
    "    if fuzzer == 'bedivfuzz-split':\n",
    "        zest_plot_data = pd.read_csv(\n",
    "            os.path.join('results', experiment_name , fuzzer, subject, f'trial-{trial}', 'zest-results', 'plot_data'),\n",
    "            skipinitialspace=True\n",
    "        )\n",
    "\n",
    "        df = pd.concat([zest_plot_data, df], ignore_index=True)\n",
    "\n",
    "    # one datapoint per minute\n",
    "    df = df.loc[np.linspace(0, len(df)-1, timeout, endpoint=True, dtype=np.int64)]\n",
    "    df['time'] = range(1, timeout+1)\n",
    "    df['trial'] = trial\n",
    "    df['fuzzer'] = fuzzer\n",
    "    df['subject'] = subject\n",
    "    df['validity_rate'] = df['valid_inputs'] / (df['valid_inputs'] + df['invalid_inputs'])\n",
    "\n",
    "    if 'unique_valid_paths' in df.columns:\n",
    "        return df[[\n",
    "            'fuzzer', 'subject', 'trial', 'time', \n",
    "            'valid_inputs', 'invalid_inputs', 'validity_rate', 'unique_paths', 'unique_valid_paths',\n",
    "            'num_coverage_probes', 'num_semantic_probes', 'b0', 'b1', 'b2'\n",
    "        ]]\n",
    "\n",
    "    else:\n",
    "        return df[[\n",
    "                'fuzzer', 'subject', 'trial', 'time', \n",
    "                'valid_inputs', 'invalid_inputs', 'validity_rate', 'unique_paths',\n",
    "                'num_coverage_probes', 'num_semantic_probes', 'b0', 'b1', 'b2'\n",
    "            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aac787e-46b9-4c51-9a85-5944f6994894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_results_to_csv(experiment_name):\n",
    "    dfs = []\n",
    "    for f, s, t in itertools.product(fuzzers, subjects, range(1, num_trials+1)):\n",
    "        dfs.append(coverage_trial_df(experiment_name, fuzzer=f, subject=s, trial=t))\n",
    "    trials = pd.concat(dfs)\n",
    "\n",
    "    trials.to_csv(\n",
    "        os.path.join('results', experiment_name, 'coverage-data.csv'),\n",
    "        index=False\n",
    "    )\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f96bfa-d7dd-40e4-affd-6aa9714aac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_default = coverage_results_to_csv('eval-bedivfuzz-split-thesis-default')\n",
    "metrics_default = coverage_results_to_csv('eval-bedivfuzz-metrics-default')\n",
    "\n",
    "thesis_semantic = coverage_results_to_csv('eval-bedivfuzz-split-thesis-semantic')\n",
    "metrics_semantic = coverage_results_to_csv('eval-bedivfuzz-metrics-semantic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbeaa53c-bb9e-4571-b896-3952268952bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_to_id = {}\n",
    "def deduplicate_crash(exception_class, stack_trace):\n",
    "    key = (exception_class, '-'.join(str(stack_trace).split('-')[:3]))\n",
    "    if str(exception_class) == 'nan':\n",
    "        return -1\n",
    "    if key in crash_to_id.keys():\n",
    "        return crash_to_id[key]\n",
    "    else:\n",
    "        crash_id = len(crash_to_id)\n",
    "        crash_to_id[key] = crash_id\n",
    "        return crash_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60459e6b-8318-442b-a927-b863bbda1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crash_trial_df(experiment_name: str, fuzzer: str, subject: str, trial: int):\n",
    "    # Read failure stats\n",
    "    df = pd.read_csv(\n",
    "        os.path.join('results', experiment_name, fuzzer, subject, f\"trial-{trial}\", 'failure_info.csv'),\n",
    "        skipinitialspace=True\n",
    "    )\n",
    "\n",
    "    # Map TTE to failure messages\n",
    "    fuzz_log = os.path.join('results', experiment_name, fuzzer, subject, f\"trial-{trial}\", 'fuzz.log')\n",
    "    tte_to_message = {}\n",
    "    if os.path.exists(fuzz_log):\n",
    "        with open(fuzz_log, 'r') as f:\n",
    "            for line in f:\n",
    "                if 'Found failure' not in line:\n",
    "                    continue\n",
    "                tokens = line.split(\" \")\n",
    "                tte = tokens[0]\n",
    "                #crash_class = tokens[6]\n",
    "                message = \" \".join(tokens[7:])\n",
    "                tte_to_message[tte] = message\n",
    "\n",
    "    df['fuzzer'] = fuzzer\n",
    "    df['subject'] = subject\n",
    "    df['trial'] = trial\n",
    "    df['tte'] = df['# ttd']\n",
    "    if not df.empty: # Assignment fails if df is empty\n",
    "        df['exception_class'] = df.apply(lambda row: str(row['exception_class']).split(\"class \")[1], axis=1)\n",
    "    df['crash_id'] = df.apply(lambda row: deduplicate_crash(row['exception_class'], row['top5_stack_trace']), axis=1)\n",
    "    df['location'] = df.apply(lambda row: ''.join(str(row['top5_stack_trace']).split('-')[:1]), axis=1)\n",
    "    df['message'] = df.apply(lambda row: tte_to_message.get(str(row['# ttd']), 'no message'), axis=1)\n",
    "    df['stack_trace'] = df['top5_stack_trace']\n",
    "\n",
    "    return df[['fuzzer', 'subject', 'trial', 'tte', 'exception_class', 'location', 'message', 'stack_trace', 'crash_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e9b3738-603d-4ff0-97f8-5ed6e2901595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crash_results_to_csv(experiment_name: str):\n",
    "    trial_crashes = []\n",
    "    for f, s, t in itertools.product(fuzzers, subjects, range(1, num_trials+1)):\n",
    "        trial_crashes.append(crash_trial_df(experiment_name, fuzzer=f, subject=s, trial=t))\n",
    "    crash_data = pd.concat(trial_crashes)\n",
    "    crash_data.to_csv(\n",
    "        os.path.join('results', experiment_name, 'crash-data.csv'),\n",
    "        index=False\n",
    "    )\n",
    "    return crash_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fec7963-93ae-405a-957f-16f400634543",
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_default = crash_results_to_csv('eval-bedivfuzz-split-thesis-default')\n",
    "metrics_default = crash_results_to_csv('eval-bedivfuzz-metrics-default')\n",
    "\n",
    "thesis_semantic = crash_results_to_csv('eval-bedivfuzz-split-thesis-semantic')\n",
    "metrics_semantic = crash_results_to_csv('eval-bedivfuzz-metrics-semantic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda98a85-fd59-4c67-98e2-92cf0a7d8c59",
   "metadata": {},
   "source": [
    "# Process ICSE22 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be952f73-7589-400e-96fb-62af24c3187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b71efcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizes the directory structure of the original artifact\n",
    "move_dirs = False\n",
    "experiment = 'eval-icse22-crashes'\n",
    "\n",
    "if move_dirs:\n",
    "    base_dir = os.path.join('results', experiment, 'java-data')\n",
    "    for d in os.listdir(base_dir):\n",
    "        results_dir = os.path.join(base_dir, d)\n",
    "        if os.path.isdir(results_dir):\n",
    "            tokens = d.split('-')\n",
    "            tech = tokens[0]\n",
    "            if tokens[1] in ['simple', 'structure']:\n",
    "                tech = f\"{tokens[0]}-{tokens[1]}\"\n",
    "                benchmark = tokens[2]\n",
    "                trial_id = f\"trial-{'-'.join(tokens[3:])}\"\n",
    "            else:\n",
    "                benchmark = tokens[1]\n",
    "                trial_id = f\"trial-{'-'.join(tokens[2:])}\" \n",
    "    \n",
    "            new_results_dir = os.path.join('results', experiment, tech)\n",
    "            if not os.path.exists(new_results_dir):\n",
    "                os.makedirs(new_results_dir)\n",
    "    \n",
    "            shutil.move(results_dir, os.path.join(new_results_dir, benchmark, trial_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d148f9-634f-41a8-a5fb-4f35547f64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzers = ['bediv-simple', 'bediv-structure', 'quickcheck', 'rl', 'zest']\n",
    "subjects = ['ant', 'closure', 'maven', 'nashorn', 'rhino', 'tomcat']\n",
    "num_trials = 30\n",
    "timeout = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce527f3-ffff-4e42-b8f7-5c6399ca5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icse_coverage_trial_df(fuzzer: str, subject: str, trial: int):\n",
    "    if fuzzer in ['quickcheck', 'rl']:\n",
    "        plot_data = os.path.join('results', 'eval-icse22-coverage', fuzzer, subject, f'trial-{trial}-replay', 'plot_data')\n",
    "    else:\n",
    "        plot_data = os.path.join('results', 'eval-icse22-coverage', fuzzer, subject, f'trial-{trial}', 'plot_data')\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        plot_data,\n",
    "        names=[\n",
    "            'unix_time', 'unique_crashes', 'total_cov', 'valid_cov', 'total_inputs', 'valid_inputs', \n",
    "            'unique_valid_paths', 'unique_valid_branch_sets', 'unique_valid_inputs', 'b0', 'b1', 'b2'],\n",
    "        header=None,\n",
    "        skiprows=1,\n",
    "        skipinitialspace=True\n",
    "    )\n",
    "\n",
    "    # two datapoints per minute\n",
    "    df = df.loc[np.linspace(0, len(df)-1, 2*timeout, endpoint=True, dtype=np.int64)]\n",
    "    df['time'] = np.arange(0.5, timeout + 0.5, 0.5)\n",
    "    df['trial'] = trial\n",
    "    df['fuzzer'] = fuzzer\n",
    "    df['subject'] = subject\n",
    "    df['validity_rate'] = df['valid_inputs'] / df['total_inputs']\n",
    "\n",
    "    return df[[\n",
    "            'fuzzer', 'subject', 'trial', 'time', \n",
    "            'valid_inputs', 'total_inputs', 'validity_rate', 'unique_valid_paths', 'b0', 'b1', 'b2'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a204f0-8d67-4177-8e75-eb75f40e25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for f, s, t in itertools.product(fuzzers, subjects, range(1, num_trials+1)):\n",
    "    dfs.append(icse_coverage_trial_df(fuzzer=f, subject=s, trial=t))\n",
    "    \n",
    "trials = pd.concat(dfs)\n",
    "trials.to_csv(\n",
    "    os.path.join('results', 'eval-icse22-coverage', 'coverage-data.csv'),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b7d7f34-2440-4bee-acc4-9b385e857a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icse_crash_trial_df(fuzzer: str, subject: str, trial: int):\n",
    "    def get_num_failures(failure_directory):\n",
    "        num_files = len([entry for entry in os.listdir(failure_directory) if os.path.isfile(os.path.join(failure_directory, entry))])\n",
    "        assert num_files % 2 == 0, failure_directory\n",
    "        return int(num_files / 2) # two files per failure\n",
    "    \n",
    "    def read_stack_trace(file):\n",
    "        with open(file, 'r') as f:\n",
    "            return '-'.join([line.strip() for line in f][1:]) # skip exception class\n",
    "\n",
    "    def read_crash_stats(file):\n",
    "        with open(file, 'r') as f:\n",
    "            lines = [line.strip() for line in f]\n",
    "            clazz = (lines[0].split(\"class \"))[1]\n",
    "            tte = (lines[1].split(\"TTD: \"))[1]\n",
    "            return clazz, int(int(tte) / 1000) # convert ms to s\n",
    "\n",
    "    # Map failure_id to failure message\n",
    "    failure_directory = os.path.join('results', 'eval-icse22-crashes', fuzzer, subject, f\"trial-{trial}\", 'failure_info')\n",
    "    fuzz_log = os.path.join('results', 'eval-icse22-crashes', fuzzer, subject, f\"trial-{trial}\", 'fuzz.log')\n",
    "    failure_id_to_message = {}\n",
    "\n",
    "    # Return empty df if no crashes have been found\n",
    "    if not os.path.exists(fuzz_log):\n",
    "        return pd.DataFrame(columns=['fuzzer', 'subject', 'trial', 'tte', 'exception_class', 'location', 'message', 'stack_trace', 'crash_id'])\n",
    "    \n",
    "    rows = []\n",
    "    with open(fuzz_log, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Found crash' not in line:\n",
    "                continue\n",
    "            tokens = line.split(\" \")\n",
    "            tte = int(int(tokens[0]) / 1000) # convert ms to s\n",
    "            failure_id = tokens[1]\n",
    "            exception_class = tokens[5]\n",
    "            message = \" \".join(tokens[7:]) if len(tokens) > 7 else 'no message'\n",
    "            stack_trace_file = os.path.join(failure_directory, f\"{failure_id}.stacktrace\")\n",
    "            stack_trace = read_stack_trace(stack_trace_file)\n",
    "\n",
    "            rows.append({\n",
    "                    'fuzzer': fuzzer,\n",
    "                    'subject': subject,\n",
    "                    'trial': trial,\n",
    "                    'tte': tte,\n",
    "                    'exception_class': exception_class,\n",
    "                    'location': stack_trace.split('-')[0],\n",
    "                    'message': message,\n",
    "                    'stack_trace': stack_trace,\n",
    "                    'crash_id': deduplicate_icse_crash(exception_class, stack_trace.split('-')[0])\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b33afb5d-44b2-42ea-a432-c1bc208fe83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this takes *a lot* of time (because quickcheck produces so many crashes)\n",
    "# Set the following flag to true if you have some spare time...\n",
    "generate_icse_crash_data = False\n",
    "\n",
    "icse_crash_to_id = {}\n",
    "def deduplicate_icse_crash(exception_class, location):\n",
    "    key = (exception_class, location)\n",
    "    if key in icse_crash_to_id.keys():\n",
    "        return icse_crash_to_id[key]\n",
    "    else:\n",
    "        crash_id = len(icse_crash_to_id)\n",
    "        icse_crash_to_id[key] = crash_id\n",
    "        return crash_id\n",
    "\n",
    "# Generate ICSE crash data csv\n",
    "if generate_icse_crash_data:\n",
    "    trial_crashes = []\n",
    "    for f, s, t in itertools.product(fuzzers, subjects, range(1, num_trials+1)):\n",
    "        trial_crashes.append(icse_crash_trial_df(fuzzer=f, subject=s, trial=t))\n",
    "        \n",
    "    crash_data = pd.concat(trial_crashes)\n",
    "    crash_data.to_csv(\n",
    "        os.path.join('results', 'eval-icse22-crashes', 'crash-data.csv'),\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6079aba8-0f1a-4613-b933-d48633603331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('java.lang.RuntimeException',\n",
       "  'com.google.javascript.jscomp.jarjar.com.google.common.base.Preconditions.checkArgument(Preconditions.java)'): 0,\n",
       " ('java.lang.StringIndexOutOfBoundsException',\n",
       "  'java.base/java.lang.StringLatin1.charAt(StringLatin1.java:47)'): 1,\n",
       " ('java.lang.RuntimeException',\n",
       "  'com.google.javascript.jscomp.InlineObjectLiterals$InliningBehavior.afterExitScope(InlineObjectLiterals.java)'): 2,\n",
       " ('java.lang.RuntimeException', ''): 3,\n",
       " ('java.lang.NullPointerException',\n",
       "  'com.google.javascript.jscomp.jarjar.com.google.common.base.Preconditions.checkNotNull(Preconditions.java)'): 4,\n",
       " ('java.lang.RuntimeException',\n",
       "  'com.google.javascript.jscomp.VarCheck.handleUndeclaredVariableRef(VarCheck.java)'): 5,\n",
       " ('java.lang.RuntimeException',\n",
       "  'com.google.javascript.jscomp.PeepholeRemoveDeadCode.tryFoldLabel(PeepholeRemoveDeadCode.java)'): 6,\n",
       " ('java.lang.AssertionError',\n",
       "  'jdk.scripting.nashorn/jdk.nashorn.internal.parser.ParserContext.pop(ParserContext.java:91)'): 7,\n",
       " ('java.lang.IllegalStateException',\n",
       "  'org.mozilla.javascript.Kit.codeBug(Kit.java)'): 8,\n",
       " ('java.lang.NullPointerException',\n",
       "  'org.mozilla.javascript.optimizer.BodyCodegen.visitObjectLiteral(BodyCodegen.java)'): 9,\n",
       " ('java.lang.NullPointerException', ''): 10,\n",
       " ('java.lang.ClassCastException',\n",
       "  'org.mozilla.javascript.Parser.destructuringAssignmentHelper(Parser.java)'): 11,\n",
       " ('java.lang.VerifyError',\n",
       "  'java.base/java.lang.Class.getDeclaredConstructors0(Native Method)'): 12,\n",
       " ('java.lang.ClassCastException', ''): 13,\n",
       " ('java.lang.NullPointerException',\n",
       "  'com.google.javascript.jscomp.jarjar.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:897)'): 14,\n",
       " ('java.lang.RuntimeException',\n",
       "  'com.google.javascript.jscomp.jarjar.com.google.common.base.Preconditions.checkArgument(Preconditions.java:301)'): 15,\n",
       " ('java.lang.RuntimeException',\n",
       "  'com.google.javascript.jscomp.InlineObjectLiterals$InliningBehavior.afterExitScope(InlineObjectLiterals.java:87)'): 16,\n",
       " ('java.lang.RuntimeException',\n",
       "  'com.google.javascript.jscomp.VarCheck.handleUndeclaredVariableRef(VarCheck.java:291)'): 17,\n",
       " ('java.lang.IllegalStateException',\n",
       "  'org.mozilla.javascript.Kit.codeBug(Kit.java:391)'): 18,\n",
       " ('java.lang.NullPointerException',\n",
       "  'org.mozilla.javascript.optimizer.BodyCodegen.visitObjectLiteral(BodyCodegen.java:2076)'): 19,\n",
       " ('java.lang.ClassCastException',\n",
       "  'org.mozilla.javascript.Parser.destructuringAssignmentHelper(Parser.java:4028)'): 20,\n",
       " ('java.lang.ClassCastException',\n",
       "  'org.mozilla.javascript.Parser.destructuringAssignmentHelper(Parser.java:4033)'): 21,\n",
       " ('java.lang.IllegalStateException',\n",
       "  'org.mozilla.javascript.Kit.codeBug(Kit.java:375)'): 22,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'org.apache.tomcat.util.digester.RulesBase.add(RulesBase.java:108)'): 23,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'java.xml/com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$ElementStack2.<init>(XMLDocumentFragmentScannerImpl.java:2053)'): 24,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'java.xml/com.sun.org.apache.xerces.internal.util.NamespaceSupport.<init>(NamespaceSupport.java:71)'): 25,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'java.base/java.util.Arrays$ArrayList.toArray(Arrays.java:4333)'): 26,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'java.base/java.util.HashMap.newNode(HashMap.java:1815)'): 27,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'org.apache.tomcat.util.digester.Digester.addCallParam(Digester.java:1555)'): 28,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'jdk.internal.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)'): 29,\n",
       " ('java.lang.OutOfMemoryError',\n",
       "  'java.xml/com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.<init>(XMLDocumentFragmentScannerImpl.java:412)'): 30,\n",
       " ('java.lang.OutOfMemoryError', ''): 31,\n",
       " ('java.lang.ArrayIndexOutOfBoundsException',\n",
       "  'org.mozilla.javascript.TokenStream.ungetChar(TokenStream.java)'): 32}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icse_crash_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7a015-3f66-4714-901d-5bcd4fd32edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
